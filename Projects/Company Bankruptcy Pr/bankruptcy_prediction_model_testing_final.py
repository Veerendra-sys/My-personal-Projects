# -*- coding: utf-8 -*-
"""Bankruptcy prediction model testing final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CaRor9TI5nRCh_lfZA-N5AfrVW6Yvh4e
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import imblearn
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, roc_auc_score
from sklearn.model_selection import GridSearchCV
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import PowerTransformer
pd.options.display.float_format = '{:,.6f}'.format
from imblearn.ensemble import BalancedBaggingClassifier
import warnings
warnings.filterwarnings("ignore")
from sklearn.naive_bayes import GaussianNB
from mpl_toolkits.mplot3d import Axes3D
from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm
from sklearn.feature_selection import VarianceThreshold
from sklearn.feature_selection import mutual_info_classif
from sklearn.linear_model import Lasso
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from imblearn.ensemble import EasyEnsembleClassifier
from sklearn.neighbors import KNeighborsClassifier
# import tensorflow as tf
# from keras.models import Sequential
# from keras.layers import Dense
# from tensorflow.keras.optimizers import Adam
# from keras.layers import Dropout
# from keras import regularizers
# from tensorflow import keras
from xgboost import XGBClassifier
pd.set_option('display.max_columns', 96)
pd.set_option('display.max_rows', 96)

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import classification_report, confusion_matrix, f1_score,accuracy_score, precision_score, recall_score, roc_auc_score

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

import warnings
warnings.filterwarnings("ignore")

# Models
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import LinearSVC, SVC
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

df=pd.read_csv("/content/data.csv")
df

df.isnull().sum().sum()

"""# MODEL TESTING

## Data Modeling
"""

#normalizing data
numeric_features = df.dtypes[df.dtypes != 'int64'].index
df[numeric_features] = df[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))

df[numeric_features] = df[numeric_features].fillna(0)

"""The numeric attributes in our dataset have been normalized to ensure consistency in scale.

Given that our dataset is highly imbalanced, we must address this issue before training any model. Below are the key steps to handle such datasets effectively:

 Splitting the Data:

The dataset is divided into 80% training and 20% testing.
The 20% test set is reserved for the final model evaluation.
 Applying Stratified K-Fold Cross-Validation:

Since the dataset is imbalanced, Stratified K-Fold ensures that class distribution remains consistent across training and validation sets.
Using Randomized Search Cross-Validation:

With over 50 features, hyperparameter tuning is crucial.
Instead of exhaustive grid search, we opt for Randomized Search Cross-Validation, which is more efficient for datasets with many features.
These steps help improve model performance while effectively handling the class imbalance issue.
"""

# Training the Model
Models = pd.DataFrame(columns=['Algorithm','Model Score','Precision','Recall','F1 score','ROC-AUC score'])

def taining_without_feature_selection(Parameters, Model, Dataframe, Modelname):

    data = Dataframe.copy()

    X = data.drop('Bankrupt?', axis=1)
    y = data['Bankrupt?']

    #Traditional split of the dataset 80% - 20%
    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    x_train, x_test, y_train, y_test = x_train.values, x_test.values, y_train.values, y_test.values

    #Proportional split of 80% data with respect to the class of the target feature ie. [1,0]
    sf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)

    for train_index, test_index in sf.split(x_train, y_train):
        sf_x_train, sf_x_test = X.iloc[train_index], X.iloc[test_index]
        sf_y_train, sf_y_test = y.iloc[train_index], y.iloc[test_index]

    sf_x_train, sf_x_test, sf_y_train, sf_y_test = sf_x_train.values, sf_x_test.values, sf_y_train.values, sf_y_test.values

    model_parameter_sm = Parameters

    rand_model = RandomizedSearchCV(Model, model_parameter_sm, n_iter=4)

    #Identifying the best parameters through RandomizedSearchCV()
    for train, test in sf.split(sf_x_train, sf_y_train):
        pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_model)
        fitting_model = pipeline.fit(sf_x_train[train], sf_y_train[train])
        best_model = rand_model.best_estimator_

    #Evaluation with against 20% unseen testing data
    print()
    print("Evaluation Of Models")

    sm = SMOTE(sampling_strategy='minority', random_state=42)
    Xsm_train, ysm_train = sm.fit_resample(sf_x_train, sf_y_train)

    print()
    print("Random Model Evaluation")

    final_model_sm = rand_model.best_estimator_
    final_model_sm.fit(Xsm_train, ysm_train)

    prediction = final_model_sm.predict(x_test)

    print(classification_report(y_test, prediction))

    model = {}

    model['Algorithm'] = Modelname
    model['Model Score'] = str(round((accuracy_score(y_test, prediction)*100),2)) + "%"
    model['Precision'] = round(precision_score(y_test, prediction),2)
    model['Recall'] = round(recall_score(y_test, prediction),2)
    model['F1 score'] = round(f1_score(y_test, prediction),2)
    model['ROC-AUC score'] = round(roc_auc_score(y_test, prediction),2)

    return model

"""Applying different algorithms"""

from sklearn.model_selection import StratifiedKFold
#K Nearest Neighbour
print("K Nearest Neighbour")
TrainedModel = taining_without_feature_selection({"n_neighbors": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}, KNeighborsClassifier(), df,"K Nearest Neighbour")
# Instead of using append, use concat to add the TrainedModel to the Models DataFrame
Models = pd.concat([Models, pd.DataFrame([TrainedModel])], ignore_index=True)

#Logistic Regression
print("Logistic Regression")
TrainedModel = taining_without_feature_selection({"penalty": ['l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, LogisticRegression(solver='liblinear'), df, "Logistic Regression")
Models = pd.concat([Models, pd.DataFrame([TrainedModel])], ignore_index=True)

#DecisionTree Classifier
print("DecisionTree Classifier")
TrainedModel = taining_without_feature_selection({"criterion": ["gini", "entropy"], "max_depth": list(range(2,4,1)),"min_samples_leaf": list(range(5,7,1))}, DecisionTreeClassifier(), df, "DecisionTree Classifier")
Models = pd.concat([Models, pd.DataFrame([TrainedModel])], ignore_index=True)

#Support Vector Classifier
print("Support Vector Classifier")
TrainedModel = taining_without_feature_selection({'C': [1,10,20],'kernel': ['rbf','linear']},  SVC(), df, "Support Vector Classifier")
Models = pd.concat([Models, pd.DataFrame([TrainedModel])], ignore_index=True

Models.sort_values('F1 score',ascending=False)

"""These are the accuraies before Dimensionality reduction techniques"""

def preprocess_inputs(df):
    df = df.copy()

    # Split df into X and y
    X = df.drop('Bankrupt?', axis=1)
    y = df['Bankrupt?']

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=1)

    # Scale X
    scaler = StandardScaler()
    scaler.fit(X_train)
    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)
    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)

    return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = preprocess_inputs(df)

y_train

original_models = {
    "                   Logistic Regression": LogisticRegression(),
    "                   K-Nearest Neighbors": KNeighborsClassifier(),
    "                         Decision Tree": DecisionTreeClassifier(),
    "Support Vector Machine (Linear Kernel)": LinearSVC(),
    "   Support Vector Machine (RBF Kernel)": SVC(),
    "                        Neural Network": MLPClassifier(),
    "                         Random Forest": RandomForestClassifier(),
    "                     Gradient Boosting": GradientBoostingClassifier()
}

for name, model in original_models.items():
    model.fit(X_train, y_train)
    print(name + " trained.")

original_results = []

for name, model in original_models.items():
    result = model.score(X_test, y_test)
    original_results.append(result)
    print(name + ": {:.2f}%".format(result * 100))

"""Dimensionality Reduction (PCA)"""

!pip install scikit-learn
import pandas as pd
from sklearn.decomposition import PCA # Import the PCA class

n_components = 10

pca = PCA(n_components=n_components) # Now PCA is defined and can be used
pca.fit(X_train)

X_train_reduced = pd.DataFrame(pca.transform(X_train), index=X_train.index, columns=["PC" + str(i) for i in range(1, n_components + 1)])
X_test_reduced = pd.DataFrame(pca.transform(X_test), index=X_test.index, columns=["PC" + str(i) for i in range(1, n_components + 1)])

X_train_reduced

!pip install plotly
import plotly.express as px # Import plotly.express and assign it to the alias 'px'

fig = px.bar(
    x=["PC" + str(i) for i in range(1, n_components + 1)],
    y=pca.explained_variance_ratio_,
    labels={'x': "Principal Component", 'y': "Variance Ratio"},
    color=pca.explained_variance_ratio_,
    color_continuous_scale=[(0, 'lightblue'), (1, 'darkblue')],
    title="Proportion of Variance in Principal Components"
)

fig.show()

"""Training the Reduced Data

"""

reduced_models = {
    "                   Logistic Regression": LogisticRegression(),
    "                   K-Nearest Neighbors": KNeighborsClassifier(),
    "                         Decision Tree": DecisionTreeClassifier(),
    "Support Vector Machine (Linear Kernel)": LinearSVC(),
    "   Support Vector Machine (RBF Kernel)": SVC(),
    "                        Neural Network": MLPClassifier(),
    "                         Random Forest": RandomForestClassifier(),
    "                     Gradient Boosting": GradientBoostingClassifier()
}

for name, model in reduced_models.items():
    model.fit(X_train_reduced, y_train)
    print(name + " trained.")

reduced_results = []

for name, model in reduced_models.items():
    result = model.score(X_test_reduced, y_test)
    reduced_results.append(result)
    print(name + ": {:.2f}%".format(result * 100))

"""Performance Change After PCA

"""

fig = px.bar(
    x=np.subtract(reduced_results, original_results),
    y=original_models.keys(),
    orientation='h',
    labels={'x': "Change in Performance", 'y': "Model"},
    color=np.subtract(reduced_results, original_results),
    color_continuous_scale=[(0, 'red'), (1, 'blue')],
    title="Change in Model Performance After Dimensionality Reduction"
)

fig.show()

"""The number of organizations that went bankrupt between 1999 and 2000 is relatively low.
Many companies hold substantial assets, which is generally a positive indicator for financial stability.
However, owning multiple assets does not guarantee immunity from bankruptcy.
A significant portion of organizations in the dataset have been operating at a loss for the past two years, as indicated by their negative net income.
Interestingly, only a small fraction of companies with negative income over the last two years have actually gone bankrupt.
Attributes such as “Debt Ratio %, Current Liability to Assets, and Current Liability to Current Assets” exhibit a strong correlation with bankruptcy.
Higher values of these attributes often lead to financial distress, increasing the likelihood of bankruptcy.
Conversely, attributes that show a negative correlation with bankruptcy play a crucial role in helping organizations stay financially stable.
There appears to be a relationship between attributes with high and low correlation with bankruptcy.


Based on the results obtained, it can be concluded that the Support Vector Machine (RBF kernel) has the best performance with an accuracy of 95.43%

The other models such as Logistic Regression, K-Nearest Neighbors, Support Vector Machine (Linear kernel), and Neural Network also perform well with an accuracy of 95.28%-94.28%.

The Decision Tree model performs comparatively poorly with an accuracy of 93.84%.

The Random Forest and Gradient Boosting models also have similar performance with an accuracy of 95.05% and 95.43%, respectively.

These results demonstrate the effectiveness of using machine learning algorithms for the task of bankruptcy prediction.

"""

df.columns

